# BulletinNotificationApp

# Sends alert to Discord at closing time for guaranteed bulletin inclusion to remind Keepers of the Bulletin to double check responses
# includes some details about whats in the spreadsheet to aid checking.

# broadly very similar to BulletinPublishApp (including the same awful logging system)

from google.oauth2 import service_account
from googleapiclient.discovery import build
from google.cloud import logging as cloud_logging
from google.cloud.logging.handlers import CloudLoggingHandler
import functions_framework


import requests
import base64
import yaml
import logging
import sys
import io
import re
import datetime
import json

# DECLARE CONSTANTS

# INITIALISE CONSTANTS TO BE POPULATED BY CONFIG FILE
GS_SPREADSHEET_ID = ""
GS_SPREADSHEET_SHEET_NAME = ""

GA_SERVICE_ACCOUNT_CREDS_PATH = ""
GA_SERVICE_ACCOUNT_PROJECT_ID = ""
GA_SCOPES = []

DIS_GENERAL_NOTIF_WEBHOOK = ""
DIS_ADMIN_NOTIF_WEBHOOK = ""

APPL_NAME = ""
APPL_ENV = ""

# Initialise global variables
numberOfEntriesInBulletin = 0

ERROR_MSG_PREPARE_ENTRIES = f'## ⏰ **CONTENT DEADLINE**: No valid entries found in Google Sheet. Ensure entries are valid by :45 to be included in Bulletin.'

# INITIALISE LOGGING

# SETUP LOGGING LOCAL BUFFER
log_buffer = io.StringIO()
bufferLoggingHandler = logging.StreamHandler(log_buffer)
bufferLoggingFormat = logging.Formatter('[BUFF] %(asctime)s - %(levelname)s - %(message)s')
bufferLoggingHandler.setFormatter(bufferLoggingFormat)

# Get the root logger and add the buffer handler
rootLoggingHandler = logging.getLogger()
rootLoggingHandler.setLevel(logging.INFO) # Set a default level (adjust as needed)
rootLoggingHandler.addHandler(bufferLoggingHandler)

consoleLoggingFormat = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
consoleLoggingHandler = logging.StreamHandler()
consoleLoggingHandler.setFormatter(consoleLoggingFormat)
rootLoggingHandler.addHandler(consoleLoggingHandler)


# Regex to parse the log line generated by our formatter
# This assumes the format: 'YYYY-MM-DD HH:MM:SS,ms - LEVELNAME - LOGGER_NAME - ENV - MESSAGE'
LOG_PARSE_REGEX = re.compile(
    r"^(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}) "
    r"- (?P<levelname>[A-Z]+) "
    r"- (?P<name>[\w.]+) "
    r"- (?P<env>[\w.]+) "
    r"- (?P<message>.*)$"
)

# Severity mapping for Cloud Logging
SEVERITY_MAP = {
    'DEBUG': 'DEBUG',
    'INFO': 'INFO',
    'WARNING': 'WARNING',
    'ERROR': 'ERROR',
    'CRITICAL': 'CRITICAL'
}

# some voodoo magic used here because we need to attach the cloud logging, after writing log entries because of reading service account credentials from file & wanting to log that!
# code produced by Gemini. No clue how or why it works but it seems to

def setupCloudLogging(credentials_path: str, project_id: str):
    rootLoggingHandler.info("Attempting to set up Google Cloud Logging...") # This log goes to buffer for now

    try:
        credentials = service_account.Credentials.from_service_account_file(credentials_path)
        client = cloud_logging.Client(
            project=project_id,
            credentials=credentials
        )

        # Parse through buffered log entries and prepare them for logging to the Cloud Logger
        buffered_logs_string = log_buffer.getvalue()
        if buffered_logs_string:
            rootLoggingHandler.info("Flushing previously buffered logs to Google Cloud Logging (chronologically)...")
            logName = f"{APPL_NAME}{APPL_ENV}"
            logger_cloud = client.logger(logName) # Get a logger object for manual logging

            for line in buffered_logs_string.splitlines():
                if not line.strip():
                    continue

                match = LOG_PARSE_REGEX.match(line)
                if match:
                    log_data = match.groupdict()
                    # Parse timestamp from string to datetime object
                    timestamp_str = log_data['timestamp'].replace(',', '.') # Convert 'ms' comma to dot for parsing
                    timestamp_dt = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S.%f')

                    # Prepare struct for Cloud Logging, includes original fields
                    log_entry_struct = {
                        "message": log_data['message'],
                        "severity": SEVERITY_MAP.get(log_data['levelname'], 'DEFAULT'),
                        "source_logger": log_data['name'],
                        "environment": log_data['env'],
                        # Add any other fields you want to extract and log as structured data
                    }
                    
                    # Manually log the text payload and structure with the original timestamp
                    logger_cloud.log_struct(
                        log_entry_struct,
                        timestamp=timestamp_dt,
                        severity=SEVERITY_MAP.get(log_data['levelname'], 'DEFAULT') # Ensure severity is also set
                    )
                else:
                    # If parsing fails, just log the raw line as INFO
                    logger_cloud.log_text(line, severity='INFO')

            rootLoggingHandler.info("Buffered logs flushed to Cloud Logging.")
        else:
            rootLoggingHandler.info("No logs were buffered before Cloud Logging setup.")


        # attach the CloudLoggingHandler for future logs
        cloudLoggingHandler = CloudLoggingHandler(client=client, name=logName)
        cloudLoggingFormat = logging.Formatter(f'{APPL_NAME} {APPL_ENV} %(asctime)s - %(levelname)s - %(message)s')
        cloudLoggingHandler.setFormatter(cloudLoggingFormat)

        rootLoggingHandler.removeHandler(bufferLoggingHandler)
        rootLoggingHandler.removeHandler(consoleLoggingHandler)
        rootLoggingHandler.addHandler(consoleLoggingHandler)
        rootLoggingHandler.addHandler(cloudLoggingHandler)

        rootLoggingHandler.info("Google Cloud Logging handler attached for future logs.")


    except Exception as e:
        # If Cloud Logging setup fails, ensure local logging remains active
        rootLoggingHandler.error(f"Failed to set up Google Cloud Logging: {e}")
        # Make sure console handler is still attached if Cloud Logging fails
        rootLoggingHandler.addHandler(consoleLoggingHandler)
        rootLoggingHandler.info("Continuing with local logging due to Cloud Logging setup failure.")


def initialise():
    """
    Initialises the program: sets global variables
    """

    logging.info("begin initialising")

    global GS_SPREADSHEET_ID, GS_SPREADSHEET_SHEET_NAME, GA_SERVICE_ACCOUNT_CREDS_PATH, GA_SERVICE_ACCOUNT_PROJECT_ID, GA_SCOPES, DIS_GENERAL_NOTIF_WEBHOOK, DIS_ADMIN_NOTIF_WEBHOOK, APPL_ENV, APPL_NAME

    try:
        with open('config.yml', 'r') as configYml:
            logging.info("opened config file")
            configData = yaml.safe_load(configYml)
    except FileNotFoundError as fnfError:
            logging.critical('file not found')
            sys.exit()
    
    # we have found the file so crack on and read it
    try:
        GS_SPREADSHEET_ID = configData['google-sheets']['spreadsheet-id']
        GS_SPREADSHEET_SHEET_NAME = configData['google-sheets']['spreadsheet-sheet-name']

        GA_SERVICE_ACCOUNT_CREDS_PATH = configData['google-auth']['service-account-creds-path']
        GA_SERVICE_ACCOUNT_PROJECT_ID = configData['google-auth']['service-account-project-id']
        GA_SCOPES = configData['google-auth']['auth-scopes']

        DIS_GENERAL_NOTIF_WEBHOOK = configData['discord']['general-notif-webhook']
        DIS_ADMIN_NOTIF_WEBHOOK = configData['discord']['admin-notif-webhook']

        APPL_NAME = configData['application']['name']
        APPL_ENV = configData['application']['environment']

        logging.info("successfully parsed all config data")

    except Exception as e:
        logging.critical(f"parsing config data into global constants: {e}")

    logging.info("complete initialisation")


def main():
    logging.info("starting main execution")

    logging.info("starting google credentials validation")

    try:
        ga_creds = None
        ga_creds = service_account.Credentials.from_service_account_file(
                                    filename=GA_SERVICE_ACCOUNT_CREDS_PATH, 
                                    scopes=GA_SCOPES)

    except Exception as e:
        logging.critical(f"failed to build service account: {e}")

    logging.info("creds validated")

    spreadsheetContents = fetchGoogleSheetsContents(ga_creds)

    try:
        if not spreadsheetContents or len(spreadsheetContents) == 1:
            # if spreadsheet is completely entry or there is just the header row: something's gone wrong...
            logging.info("no data in spreadsheet")
            postToDiscord('general', ERROR_MSG_PREPARE_ENTRIES)
        else:
            print('Data from Google Sheet:')
            for row in spreadsheetContents:
                logging.debug(f"row: {row}")
            logging.info(f'Successfully read {len(spreadsheetContents)} rows from Google Sheet')

            bulletinStateOfNation = generateBulletinStateOfNation(spreadsheetContents)
            bulletinStateOfNationText = bulletinStateOfNation[0]
            numberUnapEntries = bulletinStateOfNation[1]

            if numberOfEntriesInBulletin == 0:
                # no valid entires in the bulletin, so don't publish (ie nothing with flag set)
                postToDiscord('general', ERROR_MSG_PREPARE_ENTRIES)
            else:
                # valid bulletin as num entries >= 1
                postToDiscord('general', f'## ⏰ **CONTENT DEADLINE**: 30 Minutes Until Bulletin Published, currently {numberOfEntriesInBulletin} approved posts and {numberUnapEntries} unapproved posts. \n{bulletinStateOfNationText}')

    except Exception as e:
        logging.critical(f"error parsing spreadsheet response: {e}")
        postToDiscord('admin' f'BulletinNotificationApp: failed to parse google sheet: {e}')


def fetchGoogleSheetsContents(ga_creds: service_account.Credentials) -> list:
    logging.info("beginning sheet fetch")

    try:
        gs_service = build('sheets', 'v4', credentials=ga_creds)

        result = gs_service.spreadsheets().values().get(
            spreadsheetId=GS_SPREADSHEET_ID, range=GS_SPREADSHEET_SHEET_NAME).execute()
        values = result.get('values', [])
        return values
    except Exception as e:
        logging.critical(f"Error consuming Google Sheet: {e}")
        postToDiscord('admin' f'BulletinNotificationApp: failed to consume google sheet: {e}')


def generateBulletinStateOfNation(responseContent):
    global numberOfEntriesInBulletin

    # delete the header from the spreadsheet
    del responseContent[0]

    # sort the responses by their includeFlag so there is some control over which order they are included in
    responseContent = sorted(responseContent, key=lambda x: x[0])

    catOneEntries = ""
    catOneEntriesCount = 0
    catTwoEntries = ""
    catTwoEntriesCount = 0
    catThreeEntries = ""
    catThreeEntriesCount = 0
    unapprovedEntries = ""
    unapprovedEntriesCount = 0

    for oneRecord in responseContent:
        try:
            if oneRecord[0] == '1':
                catOneEntries += f"-> {oneRecord[6]} \n"
                catOneEntriesCount += 1
            elif oneRecord[0] == '2':
                catTwoEntries += f"-> {oneRecord[6]} \n"
                catTwoEntriesCount += 1
            elif oneRecord[0] == '3':
                catThreeEntries += f"-> {oneRecord[6]} \n"
                catThreeEntriesCount += 1
            elif oneRecord[0] == '':
                unapprovedEntries += f"-> {oneRecord[6]} \n"
                unapprovedEntriesCount +=1 
        except Exception as e:
            logging.error(f"bad bulletin entry. content {oneRecord}. error: {e}")
    
    numberOfEntriesInBulletin = catOneEntriesCount + catTwoEntriesCount + catThreeEntriesCount + unapprovedEntriesCount
    
    returnString = f'**Category 1 Entries ({catOneEntriesCount}):** \n{catOneEntries} \n **Category 2 Entries ({catTwoEntriesCount}):** \n{catTwoEntries} \n**Category 3 Entries ({catThreeEntriesCount}):** \n{catThreeEntries} \n**Unapproved Entries ({unapprovedEntriesCount}):** \n{unapprovedEntries}\n'

    return [returnString, unapprovedEntriesCount]


def postToDiscord(mode: str, content: str):
    """
    Posts to Discord either in admin or general mode
    """
    postToUrl = ""
    body = {}
    
    # match case block to set body
    match mode:
        case 'general':
            postToUrl = DIS_GENERAL_NOTIF_WEBHOOK
            body = {
                "content": content,
                "username": f"{APPL_NAME}-{APPL_ENV} Notifier"
            }
        case 'admin':
            postToUrl = DIS_ADMIN_NOTIF_WEBHOOK
            body = {
                "content": content,
                "username": f"{APPL_NAME}-{APPL_ENV} ADMIN Notifier"
            }
        case default:
            logging.error(f"invalid mode passed to postToDiscord: {mode}")
    
    logging.info(f"constructed discord webhook post: {body}")
    logging.info(f"discord webhook targeting: {postToUrl}")

    try:
        discordResult = requests.post(postToUrl, json=body)
        logging.info(f"discord posted: {discordResult}")
    except Exception as e:
        logging.critical(f"returned error from discord: {e}")
    

@functions_framework.cloud_event
def cloudHandler(launchContext):
    logging.info(launchContext)
    logging.info("--- APPLICAITON STARTUP ---")
    initialise()
    setupCloudLogging(GA_SERVICE_ACCOUNT_CREDS_PATH, GA_SERVICE_ACCOUNT_PROJECT_ID)
    main()
    logging.info("--- APPLICATION TERMINATION ---")
    return ("complete", 200)

